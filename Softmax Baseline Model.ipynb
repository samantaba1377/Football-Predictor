{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b4a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486e4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find path of each data files\n",
    "eng_path = '/Users/selbl/Desktop/PhD/Second Year/First Quarter/CS 230/Project/Data/ENG-League-2016-2020.csv'\n",
    "esp_path = '/Users/selbl/Desktop/PhD/Second Year/First Quarter/CS 230/Project/Data/ESP-League-2016-2020.csv'\n",
    "fra_path = '/Users/selbl/Desktop/PhD/Second Year/First Quarter/CS 230/Project/Data/FRA-League-2016-2020.csv'\n",
    "ger_path = '/Users/selbl/Desktop/PhD/Second Year/First Quarter/CS 230/Project/Data/GER-League-2016-2020.csv'\n",
    "ita_path = '/Users/selbl/Desktop/PhD/Second Year/First Quarter/CS 230/Project/Data/ITA-League-2016-2020.csv'\n",
    "test_path =  '/Users/selbl/Desktop/PhD/Second Year/First Quarter/CS 230/Project/Data/ENG-League-2020-2021.csv'\n",
    "#Read each dataframe\n",
    "df_eng = pd.read_csv(eng_path)\n",
    "df_esp = pd.read_csv(esp_path)\n",
    "df_fra = pd.read_csv(fra_path)\n",
    "df_ger = pd.read_csv(ger_path)\n",
    "df_ita = pd.read_csv(ita_path)\n",
    "#Combine\n",
    "df = [df_eng, df_esp, df_fra,df_ger,df_ita]\n",
    "df_train = pd.concat(df)\n",
    "#Get test data\n",
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d773fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare databases as arrays\n",
    "X_Train = np.array(df_train[['Home_Elo','Away_Elo']]).T\n",
    "X_Test = np.array(df_test[['Home_Elo','Away_Elo']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1211346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Process Y\n",
    "Y_Train = np.array(df_train['Result'])\n",
    "Y_Train.reshape(1,len(Y_Train))\n",
    "Y_Train = np.where(Y_Train == 'W',1,np.where(Y_Train=='L',0,2))\n",
    "#Same for test\n",
    "Y_Test = np.array(df_test['Result'])\n",
    "Y_Test.reshape(1,len(Y_Test))\n",
    "Y_Test = np.where(Y_Test == 'W',1,np.where(Y_Test=='L',0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f89862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define softmax\n",
    "def softmax(z):\n",
    "    \n",
    "    # z--> linear part.\n",
    "    \n",
    "    # subtracting the max of z for numerical stability.\n",
    "    exp = np.exp(z - np.max(z))\n",
    "    \n",
    "    # Calculating softmax for all examples.\n",
    "    for i in range(len(z)):\n",
    "        exp[i] /= np.sum(exp[i])\n",
    "        \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4d2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, c):\n",
    "    \n",
    "    # y--> label/ground truth.\n",
    "    # c--> Number of classes.\n",
    "    \n",
    "    # A zero matrix of size (m, c)\n",
    "    y_hot = np.zeros((len(y), c))\n",
    "    \n",
    "    # Putting 1 for column where the label is,\n",
    "    # Using multidimensional indexing.\n",
    "    y_hot[np.arange(len(y)), y] = 1\n",
    "    \n",
    "    return y_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "275a1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define fit\n",
    "def fit(X, y, lr, c, epochs):\n",
    "    \n",
    "    # X --> Input.\n",
    "    # y --> true/target value.\n",
    "    # lr --> Learning rate.\n",
    "    # c --> Number of classes.\n",
    "    # epochs --> Number of iterations.\n",
    "    \n",
    "        \n",
    "    # m-> number of training examples\n",
    "    # n-> number of features \n",
    "    m, n = X.shape\n",
    "    \n",
    "    #Normalize\n",
    "    #This is because for some reason things blow up if not\n",
    "    X = (X - np.mean(X))/(np.sqrt(np.std(X)))\n",
    "    \n",
    "    # Initializing weights and bias randomly.\n",
    "    w = np.random.randn(n, c)*0.001\n",
    "    b = np.random.randn(c)*0.001\n",
    "    # Empty list to store losses.\n",
    "    losses = []\n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Calculating hypothesis/prediction.\n",
    "        z = X@w + b\n",
    "        y_hat = softmax(z)\n",
    "        \n",
    "        # One-hot encoding y.\n",
    "        y_hot = one_hot(y, c)\n",
    "        #y_hot = y\n",
    "        \n",
    "        # Calculating the gradient of loss w.r.t w and b.\n",
    "        w_grad = (1/m)*np.dot(X.T, (y_hat - y_hot)) \n",
    "        b_grad = (1/m)*np.sum(y_hat - y_hot)\n",
    "        \n",
    "        # Updating the parameters.\n",
    "        w = w - lr*w_grad\n",
    "        b = b - lr*b_grad\n",
    "        \n",
    "        # Calculating loss and appending it in the list.\n",
    "        loss = -np.mean(np.log(y_hat[np.arange(len(y)), y]))\n",
    "        #loss = -np.mean(np.log(y_hat))\n",
    "        #loss = -np.mean(np.multiply(y,y_hat))\n",
    "        losses.append(loss)\n",
    "        # Printing out the loss at every 100th iteration.\n",
    "        if epoch%100==0:\n",
    "            print('Epoch {epoch}==> Loss = {loss}'\n",
    "                  .format(epoch=epoch, loss=loss))\n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cee18e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0==> Loss = 1.0972498820242642\n",
      "Epoch 100==> Loss = 10.264138501080259\n",
      "Epoch 200==> Loss = 10.41449928249175\n",
      "Epoch 300==> Loss = 9.839082247638407\n",
      "Epoch 400==> Loss = 13.53013492220324\n",
      "Epoch 500==> Loss = 11.38624804922244\n",
      "Epoch 600==> Loss = 12.773764659494\n",
      "Epoch 700==> Loss = 9.905831772108112\n",
      "Epoch 800==> Loss = 13.05384616954213\n",
      "Epoch 900==> Loss = 11.206010781829168\n",
      "Epoch 1000==> Loss = 12.275497885059698\n",
      "Epoch 1100==> Loss = 11.461513344560181\n",
      "Epoch 1200==> Loss = 12.837790082030683\n",
      "Epoch 1300==> Loss = 10.646485779729291\n",
      "Epoch 1400==> Loss = 9.271240715280522\n",
      "Epoch 1500==> Loss = 8.406077053121086\n",
      "Epoch 1600==> Loss = 8.199393379121588\n",
      "Epoch 1700==> Loss = 18.50045180737051\n",
      "Epoch 1800==> Loss = 8.517673001714378\n",
      "Epoch 1900==> Loss = 10.99733657254689\n",
      "Epoch 2000==> Loss = 7.054280305253326\n",
      "Epoch 2100==> Loss = 12.566720195386777\n",
      "Epoch 2200==> Loss = 9.332390091409259\n",
      "Epoch 2300==> Loss = 9.225657113147735\n",
      "Epoch 2400==> Loss = 11.34329518738569\n",
      "Epoch 2500==> Loss = 9.879423745329424\n",
      "Epoch 2600==> Loss = 15.026742467133616\n",
      "Epoch 2700==> Loss = 9.127035481486757\n",
      "Epoch 2800==> Loss = 10.05707710354053\n",
      "Epoch 2900==> Loss = 7.836676217466176\n",
      "Epoch 3000==> Loss = 9.315034815140569\n",
      "Epoch 3100==> Loss = 9.223191622185315\n",
      "Epoch 3200==> Loss = 8.704007605702108\n",
      "Epoch 3300==> Loss = 8.047063676828492\n",
      "Epoch 3400==> Loss = 14.398577890108601\n",
      "Epoch 3500==> Loss = 10.612043939739232\n",
      "Epoch 3600==> Loss = 8.985380396570996\n",
      "Epoch 3700==> Loss = 8.17810972027261\n",
      "Epoch 3800==> Loss = 14.28606876528361\n",
      "Epoch 3900==> Loss = 8.042515491441316\n",
      "Epoch 4000==> Loss = 10.3507919273611\n",
      "Epoch 4100==> Loss = 7.9591434333671405\n",
      "Epoch 4200==> Loss = 11.79892633443707\n",
      "Epoch 4300==> Loss = 17.87159271746385\n",
      "Epoch 4400==> Loss = 14.099795087124102\n",
      "Epoch 4500==> Loss = 9.141158702145617\n",
      "Epoch 4600==> Loss = 9.14234226991182\n",
      "Epoch 4700==> Loss = 14.82116264968806\n",
      "Epoch 4800==> Loss = 10.352171487660671\n",
      "Epoch 4900==> Loss = 7.248548543029871\n"
     ]
    }
   ],
   "source": [
    "#Fit\n",
    "w, b, l = fit(X_Train.T, Y_Train, lr=0.8, c=3, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b2021c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we set the criteria to evaluate model\n",
    "def predict(X, w, b):\n",
    "    \n",
    "    # X --> Input.\n",
    "    # w --> weights.\n",
    "    # b --> bias.\n",
    "    \n",
    "    # Predicting\n",
    "    z = X@w + b\n",
    "    y_hat = softmax(z)\n",
    "    \n",
    "    # Returning the class with highest probability.\n",
    "    return np.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cef5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    return np.sum(y==y_hat)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67bc66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the train set is: 0.2514862436056961\n",
      "The accuracy for the test set is: 0.21578947368421053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-9d332b99be9c>:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  exp[i] /= np.sum(exp[i])\n"
     ]
    }
   ],
   "source": [
    "#Measurements\n",
    "# Accuracy for training set.\n",
    "train_preds = predict(X_Train.T, w, b)\n",
    "acc_train = accuracy(Y_Train, train_preds)\n",
    "print('The accuracy for the train set is: ' + str(acc_train))\n",
    "# Accuracy for test set.\n",
    "# Flattening and normalizing.\n",
    "test_preds = predict(X_Test.T, w, b)\n",
    "acc_test = accuracy(Y_Test, test_preds)\n",
    "print('The accuracy for the test set is: ' + str(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e79bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
